{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-05 20:38:15,698 - INFO - Папка 'Image' со старыми данными была удалена\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-05 20:38:35,899 - INFO - Завершена обработка всех URL\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import re\n",
    "import os\n",
    "import pandas as pd\n",
    "import shutil\n",
    "import logging\n",
    "import psycopg2\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, format=\"%(asctime)s - %(levelname)s - %(message)s\")\n",
    "\n",
    "def fetch_data(url):\n",
    "    data = []\n",
    "    \n",
    "    if os.path.exists(\"Image\") and os.path.isdir(\"Image\"):\n",
    "        shutil.rmtree(\"Image\")\n",
    "        logging.info(\"Папка 'Image' со старыми данными была удалена\")\n",
    "    \n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()\n",
    "        response_text = response.text\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        logging.error(f\"Ошибка при выполнении запроса для {url}: {e}\")\n",
    "        return pd.DataFrame(columns=[\"name\", \"description\", \"image\", \"town\", \"type\"])\n",
    "    \n",
    "    pattern = re.compile(\n",
    "        r'{\"name\":\"(?P<name>.*?)\",.*?\"description\":\"(?P<description>.*?)\",.*?\"image\":\"(?P<image>.*?)\"}'\n",
    "    )\n",
    "    \n",
    "    try:\n",
    "        for match in pattern.finditer(response_text):\n",
    "            name = match.group(\"name\")\n",
    "            description = match.group(\"description\")\n",
    "            image = match.group(\"image\")\n",
    "            if name and description and image:\n",
    "                data.append({\n",
    "                    \"name\": name,\n",
    "                    \"description\": description,\n",
    "                    \"image\": image\n",
    "                })\n",
    "            else:\n",
    "                logging.warning(f\"Пропущена запись из-за отсутствующих данных для {url}: {match.groupdict()}\")\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Ошибка при парсинге данных для {url}: {e}\")\n",
    "        return pd.DataFrame(columns=[\"name\", \"description\", \"image\", \"town\", \"type\"])\n",
    "\n",
    "    try:\n",
    "        df = pd.DataFrame(data, columns=[\"name\", \"description\", \"image\"])\n",
    "        if df.empty:\n",
    "            logging.warning(f\"Данные не найдены или не удалось их распарсить для {url}.\")\n",
    "        else:\n",
    "            if \"spb\" in url:\n",
    "                df[\"town\"] = \"Санкт-Петербург\"\n",
    "            else:\n",
    "                df[\"town\"] = \"Москва\"\n",
    "            if \"cinema\" in url:\n",
    "                df[\"type\"] = \"cinema\"\n",
    "            elif \"theatre\" in url:\n",
    "                df[\"type\"] = \"theatre\"\n",
    "            elif \"concerts\" in url:\n",
    "                df[\"type\"] = \"concerts\"\n",
    "            elif \"exhibitions\" in url:\n",
    "                df[\"type\"] = \"exhibitions\"\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Ошибка при создании DataFrame для {url}: {e}\")\n",
    "        return pd.DataFrame(columns=[\"name\", \"description\", \"image\", \"town\", \"type\"])\n",
    "\n",
    "urls = [\n",
    "    \"https://www.afisha.ru/spb/cinema/\",\n",
    "    \"https://www.afisha.ru/spb/theatre/\",\n",
    "    \"https://www.afisha.ru/spb/concerts/\",\n",
    "    \"https://www.afisha.ru/spb/exhibitions/\",\n",
    "    \"https://www.afisha.ru/msk/cinema/\",\n",
    "    \"https://www.afisha.ru/msk/theatre/\",\n",
    "    \"https://www.afisha.ru/msk/concerts/\"\n",
    "]\n",
    "\n",
    "parsed_data = pd.DataFrame()\n",
    "for url in urls:\n",
    "    df = fetch_data(url)\n",
    "    parsed_data = pd.concat([parsed_data, df], ignore_index=True)\n",
    "\n",
    "logging.info(\"Завершена обработка всех URL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_correct_url(url):\n",
    "    match = re.search(r'(https?://\\S+\\.(?:jpg|jpeg|png|gif|webp))', url)\n",
    "    if match:\n",
    "        return match.group(1)\n",
    "    return None\n",
    "\n",
    "def clean_df(df):\n",
    "    def has_unwanted_chars(description):\n",
    "        if not isinstance(description, str):\n",
    "            return False\n",
    "        if re.search(r\"<[^>]*>\", description):\n",
    "            return True\n",
    "        return False\n",
    "    df_cleaned = df[~df['description'].apply(has_unwanted_chars)]\n",
    "    return df_cleaned\n",
    "\n",
    "clean_data = (clean_df(parsed_data)\n",
    "              .assign(image=lambda x: x['image'].apply(make_correct_url))\n",
    "              .drop_duplicates(subset=['name', 'town', 'type'])\n",
    "              .reset_index(drop=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-05 20:40:11,715 - INFO - Обработка завершена\n"
     ]
    }
   ],
   "source": [
    "image_folder = \"Image\"\n",
    "paths = []\n",
    "\n",
    "if not os.path.exists(image_folder):\n",
    "    os.makedirs(image_folder)\n",
    "\n",
    "def download_image(url, folder, filename):\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()\n",
    "\n",
    "        file_path = os.path.join(folder, filename)\n",
    "        with open(file_path, 'wb') as f:\n",
    "            f.write(response.content)\n",
    "        return file_path\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        logging.error(f\"Ошибка при скачивании {url}: {e}\")\n",
    "        if response is not None:\n",
    "            logging.error(f\"Ответ сервера: {response.status_code} - {response.text[:100]}\")\n",
    "        return None\n",
    "    \n",
    "for index, row in clean_data.iterrows():\n",
    "    image_url = row[\"image\"]\n",
    "    if pd.notna(image_url) and isinstance(image_url, str):\n",
    "        if image_url:\n",
    "            filename = f\"image_{index}.jpg\"\n",
    "            file_path = download_image(image_url, image_folder, filename)\n",
    "            if file_path:\n",
    "                paths.append(file_path)\n",
    "            else:\n",
    "                paths.append(None)\n",
    "        else:\n",
    "            logging.warning(f\"Некорректный URL: {image_url}\")\n",
    "            paths.append(None)\n",
    "    else:\n",
    "        paths.append(None)\n",
    "\n",
    "clean_data['path'] = paths\n",
    "clean_data.drop(columns=['image'], inplace=True)\n",
    "\n",
    "logging.info(\"Обработка завершена\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-05 20:41:47,441 - INFO - Подключение к базе данных успешно выполнено\n",
      "2025-01-05 20:41:47,456 - INFO - Таблица создана или уже существует\n",
      "2025-01-05 20:41:47,559 - INFO - Данные успешно записаны в базу данных\n",
      "2025-01-05 20:41:47,560 - INFO - Соединение с базой данных закрыто\n"
     ]
    }
   ],
   "source": [
    "connection_line = \"dbname='events' user='postgres' password='postgres' host='localhost' sslmode='disable'\"\n",
    "\n",
    "try:\n",
    "    conn = psycopg2.connect(connection_line)\n",
    "    cursor = conn.cursor()\n",
    "    logging.info(\"Подключение к базе данных успешно выполнено\")\n",
    "except Exception as e:\n",
    "    logging.error(f\"Ошибка подключения к базе данных: {e}\")\n",
    "\n",
    "query = \"\"\"\n",
    "CREATE TABLE IF NOT EXISTS events (\n",
    "    name VARCHAR(500) NOT NULL,\n",
    "    description VARCHAR(500) NOT NULL,\n",
    "    town VARCHAR(500) NOT NULL,\n",
    "    type VARCHAR(500) NOT NULL,\n",
    "    path VARCHAR(500) NOT NULL\n",
    ");\n",
    "TRUNCATE TABLE events;\n",
    "\"\"\"\n",
    "\n",
    "try:\n",
    "    cursor.execute(query)\n",
    "    conn.commit()\n",
    "    logging.info(\"Таблица создана или уже существует\")\n",
    "except Exception as e:\n",
    "    logging.error(f\"Ошибка при создании таблицы: {e}\")\n",
    "\n",
    "def insert_data(df, conn):\n",
    "    try:\n",
    "        for index, row in df.iterrows():\n",
    "            cursor.execute(\"\"\"\n",
    "                INSERT INTO events (name, description, town, type, path)\n",
    "                VALUES (%s, %s, %s, %s, %s)\n",
    "            \"\"\", (row['name'], row['description'], row['town'], row['type'], row['path']))\n",
    "        conn.commit()\n",
    "        logging.info(\"Данные успешно записаны в базу данных\")\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Ошибка при записи данных: {e}\")\n",
    "        conn.rollback()\n",
    "\n",
    "insert_data(clean_data, conn)\n",
    "\n",
    "cursor.close()\n",
    "conn.close()\n",
    "logging.info(\"Соединение с базой данных закрыто\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
